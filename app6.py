from flask import Flask, request, render_template_string, redirect, url_for, send_file
import fitz
from PIL import Image
import pytesseract
import os, uuid # 'os' Ã© importante aqui
from werkzeug.utils import secure_filename
import google.generativeai as genai
import json
import speech_recognition as sr
import pyttsx3
import io
from pydub import AudioSegment
import tempfile # Ainda usaremos tempfile, mas direcionaremos sua base

# --- ConfiguraÃ§Ãµes Iniciais ---
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

app = Flask(__name__)

genai.configure(api_key="")

model = genai.GenerativeModel('models/gemini-2.0-flash')

engine = pyttsx3.init()
voices = engine.getProperty('voices')
for voice in voices:
    if "brazil" in voice.name.lower() or "portuguese" in voice.name.lower():
        engine.setProperty('voice', voice.id)
        break
else:
    engine.setProperty('voice', voices[0].id)
engine.setProperty('rate', 150)
engine.setProperty('volume', 1.0)
# --- Fim das ConfiguraÃ§Ãµes Iniciais ---

# --- DefiniÃ§Ã£o da Pasta TemporÃ¡ria Customizada ---
# Pega o diretÃ³rio do script atual e anexa 'temp_audios'
# Isso garante que a pasta temporÃ¡ria seja relativa ao seu projeto
CUSTOM_TEMP_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'temp_audios')

# Garante que o diretÃ³rio exista. Se nÃ£o existir, ele serÃ¡ criado.
os.makedirs(CUSTOM_TEMP_DIR, exist_ok=True)

# Opcional: Define a variÃ¡vel de ambiente TEMP para a sua pasta customizada
# Isso faz com que 'tempfile' use essa pasta por padrÃ£o para tudo,
# mas podemos ser mais especÃ­ficos na rota.
# os.environ['TMPDIR'] = CUSTOM_TEMP_DIR # Para sistemas Unix-like
# os.environ['TEMP'] = CUSTOM_TEMP_DIR Â  # Para Windows
# os.environ['TMP'] = CUSTOM_TEMP_DIR Â  Â # Para Windows
# ^^^ Comentadas, pois vamos passar 'dir' diretamente para NamedTemporaryFile

INDEX_HTML = '''
<!DOCTYPE html>
<html lang="pt-BR">
<head>
Â  Â  <meta charset="UTF-8">
Â  Â  <title>Leitor AcessÃ­vel</title>
Â  Â  <style>
Â  Â  Â  Â  body { font-family: Arial, sans-serif; padding: 20px; background-color: #f5f5f5; }
Â  Â  Â  Â  .container { max-width: 600px; margin: auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
Â  Â  </style>
</head>
<body>
<div class="container">
Â  Â  <h1>ğŸ§  Leitor AcessÃ­vel</h1>
Â  Â  <form method="POST" action="/ocr" enctype="multipart/form-data">
Â  Â  Â  Â  <label>Escolha um arquivo PDF ou imagem:</label><br>
Â  Â  Â  Â  <input type="file" name="file" accept="image/*,.pdf" required><br><br>
Â  Â  Â  Â  <button type="submit">ğŸ“„ Processar OCR</button>
Â  Â  </form>
</div>
</body>
</html>
'''

RESULT_HTML = '''
<!DOCTYPE html>
<html lang="pt-BR">
<head>
Â  <meta charset="UTF-8">
Â  <title>{{ filename }}</title>
Â  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
Â  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/antijingoist/open-dyslexic@master/open-dyslexic-regular.css">
Â  <link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible&family=Lexend&display=swap" rel="stylesheet">
Â  <style>
Â  Â  body { font-family: Verdana, Arial, sans-serif; line-height: 1.6; padding: 20px; background-color: #f0f0f0; color: #333; }

Â  Â  #accessibility-controls {
Â  Â  Â  position: sticky; top: 0; z-index: 1000;
Â  Â  Â  padding: 10px; margin-bottom: 20px;
Â  Â  Â  border: 1px solid; border-radius: 5px;
Â  Â  }

Â  Â  body.normal-mode #accessibility-controls {
Â  Â  Â  background-color: #e0e0e0; border-color: #ccc; color: #000;
Â  Â  }

Â  Â  body.dark-mode #accessibility-controls {
Â  Â  Â  background-color: #1e1e1e; border-color: #444; color: #fff;
Â  Â  }

Â  Â  body.high-contrast-mode #accessibility-controls {
Â  Â  Â  background-color: #000; border-color: #00FF00; color: #00FF00;
Â  Â  }

Â  Â  #accessibility-controls button,
Â  Â  #accessibility-controls select {
Â  Â  Â  margin: 0 5px; padding: 5px 10px; cursor: pointer;
Â  Â  }

Â  Â  .page-content {
Â  Â  Â  background-color: #fff; padding: 15px;
Â  Â  Â  margin-bottom: 20px; border: 1px solid #ddd;
Â  Â  Â  border-radius: 3px;
Â  Â  }

Â  Â  body.normal-mode { background-color: #f0f0f0; color: #333; }
Â  Â  body.dark-mode { background-color: #121212; color: #ffffff; }
Â  Â  body.high-contrast-mode { background-color: #000000; color: #00FF00; }

Â  Â  body.normal-mode .page-content { background-color: #ffffff; border-color: #dddddd; }
Â  Â  body.dark-mode .page-content { background-color: #1e1e1e; border-color: #444444; }
Â  Â  body.high-contrast-mode .page-content { background-color: #000000; border-color: #00FF00; }

Â  Â  h1, h2, h3 {
Â  Â  Â  border-bottom: 1px solid; padding-bottom: 0.3em;
Â  Â  }

Â  Â  body.normal-mode h1, body.normal-mode h2, body.normal-mode h3 {
Â  Â  Â  color: #000; border-color: #eee;
Â  Â  }

Â  Â  body.dark-mode h1, body.dark-mode h2, body.dark-mode h3 {
Â  Â  Â  color: #fff; border-color: #444;
Â  Â  }

Â  Â  body.high-contrast-mode h1, body.high-contrast-mode h2, body.high-contrast-mode h3 {
Â  Â  Â  color: #00FF00; border-color: #00FF00;
Â  Â  }

Â  Â  hr.page-separator {
Â  Â  Â  margin-top: 2em; margin-bottom: 2em;
Â  Â  Â  border: 1px dashed #ccc;
Â  Â  }

Â  Â  hr.footnotes-separator {
Â  Â  Â  margin-top: 1.5em; margin-bottom: 1em;
Â  Â  Â  border-style: dotted; border-width: 1px 0 0 0;
Â  Â  }

Â  Â  .footnotes-section { margin-top: 1em; padding-top: 0.5em; }
Â  Â  .footnotes-list { list-style-type: decimal; padding-left: 20px; font-size: 0.9em; }
Â  Â  .footnotes-list li { margin-bottom: 0.5em; }
Â  Â  .footnotes-list li a { text-decoration: none; }

Â  Â  .sr-only {
Â  Â  Â  position: absolute; width: 1px; height: 1px;
Â  Â  Â  padding: 0; margin: -1px; overflow: hidden;
Â  Â  Â  clip: rect(0, 0, 0, 0); white-space: nowrap; border-width: 0;
Â  Â  }

Â  Â  p i, span i { color: #555; font-style: italic; }

Â  Â  sup > a { text-decoration: none; color: #0066cc; }
Â  Â  sup > a:hover { text-decoration: underline; }
Â  </style>
</head>

<body class="normal-mode">
Â  Â  <div id="accessibility-controls">
Â  Â  <span>Tamanho da Fonte:</span>
Â  Â  <button id="decreaseFont">A-</button>
Â  Â  <button id="increaseFont">A+</button>

Â  Â  <label for="fontSelector">Fonte:</label>
Â  Â  <select id="fontSelector">
Â  Â  Â  <option>Atkinson Hyperlegible</option>
Â  Â  Â  <option>Lexend</option>
Â  Â  Â  <option>OpenDyslexicRegular</option>
Â  Â  Â  <option>Verdana</option>
Â  Â  Â  <option>Arial</option>
Â  Â  Â  <option>Times New Roman</option>
Â  Â  Â  <option>Courier New</option>
Â  Â  </select>

Â  Â  <span>Leitura:</span>
Â  Â  <button id="play">â–¶ï¸</button>
Â  Â  <button id="pause">â¸ï¸</button>
Â  Â  <button id="stop">â¹ï¸</button>

Â  Â  <label for="themeSelector">Tema:</label>
Â  Â  <select id="themeSelector">
Â  Â  Â  <option value="normal">Normal</option>
Â  Â  Â  <option value="dark">Modo Escuro</option>
Â  Â  Â  <option value="high-contrast">Alto Contraste</option>
Â  Â  </select>

Â  Â  <button onclick="copyText()">ğŸ“‹ Copiar</button>
Â  Â  <button onclick="saveHTML()">ğŸ’¾ Salvar</button>

    <button id="talkToAI">ğŸ—£ï¸ Falar com IA</button>
    <span id="recordingStatus" style="margin-left: 10px; color: red;"></span>
Â  </div>

Â  Â  <div class="page-content">
Â  Â  <h1>Resultado OCR â€“ {{ filename }}</h1>
Â  Â  <div>{{ text|safe }}</div>

Â  Â  <form method="POST" action="/gerar_html">
Â  Â  Â  <input type="hidden" name="ocr_texto" value="{{ text|e }}">
Â  Â  Â  <button type="submit">ğŸ§  Reestruturar com IA (Gemini)</button>
Â  Â  </form>

Â  Â  <div class="actions">
Â  Â  Â  <a href="/">â† Voltar</a>
Â  Â  </div>
Â  </div>

Â  Â  <script>
Â  Â  let currentFontSize = 16;
Â  Â  const fonts = ['Atkinson Hyperlegible','Lexend','OpenDyslexicRegular','Verdana','Arial','Times New Roman','Courier New'];
Â  Â  let currentFontIndex = 0;
Â  Â  const synth = window.speechSynthesis;
Â  Â  let utterance, isPaused = false;
    let mediaRecorder;
    let audioChunks = [];
    const talkToAIButton = document.getElementById('talkToAI');
    const recordingStatus = document.getElementById('recordingStatus');

Â  Â  function applyFontSize() {
Â  Â  Â  document.querySelectorAll('.page-content').forEach(el => {
Â  Â  Â  Â  el.style.fontSize = currentFontSize + 'px';
Â  Â  Â  });
Â  Â  }

Â  Â  function applyFontFamily() {
Â  Â  Â  const ff = fonts[currentFontIndex];
Â  Â  Â  document.querySelectorAll('.page-content').forEach(el => {
Â  Â  Â  Â  el.style.fontFamily = ff + ', sans-serif';
Â  Â  Â  });
Â  Â  }

Â  Â  function changeTheme(mode) {
Â  Â  Â  document.body.classList.remove('normal-mode','dark-mode','high-contrast-mode');
Â  Â  Â  document.body.classList.add(mode + '-mode');
Â  Â  }

Â  Â  function getTextToSpeak() {
Â  Â  Â  const sel = window.getSelection().toString();
Â  Â  Â  return sel || document.querySelector('.page-content').innerText;
Â  Â  }

Â  Â  function speak() {
Â  Â  Â  const text = getTextToSpeak();
Â  Â  Â  if (!text) return alert('Nada para ler');
Â  Â  Â  if (synth.speaking) return;
Â  Â  Â  utterance = new SpeechSynthesisUtterance(text);
Â  Â  Â  utterance.lang = 'pt-BR';
Â  Â  Â  synth.speak(utterance);
Â  Â  }

Â  Â  function pauseSpeech() { if (synth.speaking) { synth.pause(); isPaused = true; } }
Â  Â  function resumeSpeech() { if (isPaused) { synth.resume(); isPaused = false; } }
Â  Â  function stopSpeech() { synth.cancel(); isPaused = false; }

Â  Â  document.getElementById('decreaseFont').onclick = () => {
Â  Â  Â  currentFontSize = Math.max(10, currentFontSize - 2);
Â  Â  Â  applyFontSize();
Â  Â  };
Â  Â  document.getElementById('increaseFont').onclick = () => {
Â  Â  Â  currentFontSize = Math.min(40, currentFontSize + 2);
Â  Â  Â  applyFontSize();
Â  Â  };
Â  Â  document.getElementById('fontSelector').onchange = e => {
Â  Â  Â  currentFontIndex = fonts.indexOf(e.target.value);
Â  Â  Â  applyFontFamily();
Â  Â  };

Â  Â  document.getElementById('play').onclick = () => {
Â  Â  Â  if (isPaused) resumeSpeech();
Â  Â  Â  else speak();
Â  Â  };
Â  Â  document.getElementById('pause').onclick = pauseSpeech;
Â  Â  document.getElementById('stop').onclick = stopSpeech;

Â  Â  document.getElementById('themeSelector').onchange = e => {
Â  Â  Â  changeTheme(e.target.value);
Â  Â  };

Â  Â  function copyText() {
Â  Â  Â  const text = document.querySelector('.page-content').innerText;
Â  Â  Â  navigator.clipboard.writeText(text).then(() => alert('Texto copiado!'));
Â  Â  }

Â  Â  function saveHTML() {
Â  Â  Â  const content = document.documentElement.outerHTML;
Â  Â  Â  const blob = new Blob([content], { type: 'text/html' });
Â  Â  Â  const link = document.createElement('a');
Â  Â  Â  link.href = URL.createObjectURL(blob);
Â  Â  Â  link.download = 'documento_acessivel.html';
Â  Â  Â  link.click();
Â  Â  }

    // LÃ“GICA PARA INTERAÃ‡ÃƒO COM A IA POR VOZ - AJUSTADA PARA GARANTIR COMPATIBILIDADE
    talkToAIButton.onclick = async () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            talkToAIButton.textContent = 'ğŸ—£ï¸ Falar com IA';
            recordingStatus.textContent = '';
        } else {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Definir o mimeType para WebM com Opus, que Ã© um formato eficiente e amplamente suportado
                // pelo MediaRecorder e que o pydub consegue lidar bem.
                const options = { mimeType: 'audio/webm;codecs=opus' };
                mediaRecorder = new MediaRecorder(stream, options);
                
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType }); // Usa o tipo MIME real da gravaÃ§Ã£o
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'query.webm'); // Envia como .webm

                    recordingStatus.textContent = 'Enviando e processando...';

                    try {
                        const response = await fetch('/ask_ai_voice', {
                            method: 'POST',
                            body: formData
                        });

                        if (response.ok) {
                            const audioResponseBlob = await response.blob();
                            const audioUrl = URL.createObjectURL(audioResponseBlob);
                            const audio = new Audio(audioUrl);
                            audio.onended = () => {
                                recordingStatus.textContent = 'Pronto!';
                            };
                            audio.play();
                        } else {
                            const errorText = await response.text();
                            recordingStatus.textContent = `Erro: ${errorText}`;
                            alert('Erro ao se comunicar com a IA: ' + errorText);
                        }
                    } catch (error) {
                        recordingStatus.textContent = `Erro de rede: ${error.message}`;
                        console.error('Erro ao enviar Ã¡udio para a IA:', error);
                        alert('Erro de conexÃ£o ao enviar Ã¡udio.');
                    } finally {
                        stream.getTracks().forEach(track => track.stop()); // Para o microfone
                    }
                };

                mediaRecorder.start();
                talkToAIButton.textContent = 'ğŸ”´ Parar GravaÃ§Ã£o';
                recordingStatus.textContent = 'Gravando...';
            } catch (error) {
                console.error('Erro ao acessar o microfone:', error);
                alert('NÃ£o foi possÃ­vel acessar o microfone. Verifique as permissÃµes.');
            }
        }
    };


Â  Â  document.addEventListener('DOMContentLoaded', () => {
Â  Â  Â  applyFontSize();
Â  Â  Â  applyFontFamily();
Â  Â  Â  changeTheme('normal');
Â  Â  Â  document.getElementById('fontSelector').value = fonts[0];
Â  Â  Â  document.getElementById('themeSelector').value = 'normal';
Â  Â  });
Â  </script>
</body>
</html>
'''


def gerar_html_acessivel_com_gemini(texto_ocr):
    prompt = f"""
    VocÃª Ã© uma IA que transforma textos escaneados via OCR em documentos HTML acessÃ­veis.
    Suas tarefas incluem:
    - Corrigir erros de OCR
    - Detectar e formatar tÃ­tulos, listas, tabelas e seÃ§Ãµes
    - Converter equaÃ§Ãµes para LaTeX (exibidas com MathJax)
    - Estruturar o conteÃºdo com marcaÃ§Ã£o HTML limpa
    - Tornar o conteÃºdo ideal para leitores de tela
    VocÃª atuarÃ¡ como um conversor de expressÃµes matemÃ¡ticas para uma versÃ£o descritiva, em linguagem natural, ideal para leitores de tela e acessibilidade web.
    O conteÃºdo a seguir Ã© extraÃ­do por OCR a partir de documentos didÃ¡ticos contendo expressÃµes matemÃ¡ticas (como derivadas, limites, integrais, funÃ§Ãµes, matrizes, planilhas etc).
    Sua tarefa Ã©:
    1. Corrigir qualquer erro ortogrÃ¡fico ou de OCR;
    2. Converter expressÃµes matemÃ¡ticas para texto descritivo, seguindo os exemplos abaixo;
    3. Manter o conteÃºdo formatado com marcaÃ§Ã£o HTML simples e/ou MathJax (`\( ... \)` para inline e `$$ ... $$` para blocos);
    4. Retornar o resultado em **HTML completo**, pronto para ser exibido em navegadores com suporte a leitores automÃ¡ticos.
    ### Exemplo de ConversÃµes:
    `f(x) = x^2 + 1` â†’ `A funÃ§Ã£o f de x Ã© igual a x ao quadrado mais um. Escrito como \( f(x) = x^2 + 1 \)`
    `lim xâ†’0 f(x)` â†’ `O limite de f de x quando x tende a zero. Escrito como 
    `âˆ«x^2 dx` â†’ `A integral de x ao quadrado em relaÃ§Ã£o a x. Escrito como
    `2,34` â†’ `dois vÃ­rgula trÃªs quatro`
    `Matriz [[1, 2], [3, 4]]` â†’ `Matriz de duas linhas e duas colunas com os elementos: primeira linha um e dois, segunda linha trÃªs e quatro`
    `f'(x)` â†’ `Derivada da funÃ§Ã£o f em relaÃ§Ã£o a x. Escrito como \( f'(x) \)`
    `|x|` â†’ `Valor absoluto de x. Escrito como \( |x| \)`
    `Î”x` â†’ `VariaÃ§Ã£o de x. Escrito como \( \Delta x \)`
    ### Importante:
    - Sempre que possÃ­vel, forneÃ§a as duas formas: descritiva e matemÃ¡tica.
- Mantenha tÃ­tulos, subtÃ­tulos e parÃ¡grafos intactos, substituindo apenas os trechos matemÃ¡ticos ou ambÃ­guos.
- Conserve os separadores visuais e use HTML para listas, Ãªnfases e headings.
- Retorne o resultado em HTML **completo** entre `<html>...</html>`.

    Gere o corpo HTML (sem <html> ou <head>), apenas o conteÃºdo principal com marcaÃ§Ã£o semÃ¢ntica:


    Texto OCR:
    \"\"\"{texto_ocr}\"\"\"
    """

    response = model.generate_content(prompt)
    return response.text

# Nova funÃ§Ã£o para interagir com a IA por voz
def ask_gemini_and_get_audio(text_input):
    prompt = f"O usuÃ¡rio perguntou: '{text_input}'. Responda de forma concisa e Ãºtil."
    ai_response = model.generate_content(prompt).text

    audio_buffer = io.BytesIO()
    try:
        # Usa a pasta temporÃ¡ria customizada para o pyttsx3 tambÃ©m
        with tempfile.NamedTemporaryFile(delete=True, suffix=".wav", dir=CUSTOM_TEMP_DIR) as fp:
            engine.save_to_file(ai_response, fp.name)
            engine.runAndWait()
            fp.seek(0)
            audio_buffer.write(fp.read())
        audio_buffer.seek(0)
    except Exception as e:
        print(f"Erro ao gerar Ã¡udio com pyttsx3: {e}")
        error_message = "Desculpe, tive um problema ao gerar a resposta de Ã¡udio."
        try:
            with tempfile.NamedTemporaryFile(delete=True, suffix=".wav", dir=CUSTOM_TEMP_DIR) as fp:
                engine.save_to_file(error_message, fp.name)
                engine.runAndWait()
                fp.seek(0)
                audio_buffer.write(fp.read())
            audio_buffer.seek(0)
        except Exception as inner_e:
            print(f"Erro ao gerar mensagem de erro de Ã¡udio de fallback: {inner_e}")
            audio_buffer = io.BytesIO()
        ai_response = error_message

    return audio_buffer, ai_response

@app.route('/')
def index():
    return render_template_string(INDEX_HTML)

@app.route('/ocr', methods=['POST'])
def ocr():
    uploaded = request.files.get('file')
    if not uploaded:
        return redirect(url_for('index'))

    original_name = secure_filename(uploaded.filename)
    tmp_dir = 'tmp' # Esta Ã© para OCR, pode manter separada ou integrar na nova, mas Ã© diferente da de Ã¡udio
    os.makedirs(tmp_dir, exist_ok=True)
    tmp_name = f"tmp_{uuid.uuid4().hex}_{original_name}"
    tmp_path = os.path.join(tmp_dir, tmp_name)
    uploaded.save(tmp_path)

    texts = []
    ext = os.path.splitext(original_name)[1].lower()

    try:
        if ext == '.pdf':
            doc = fitz.open(tmp_path)
            for page in doc:
                pix = page.get_pixmap(dpi=200, alpha=False)
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                txt = pytesseract.image_to_string(img, lang='por+eng')
                texts.append(txt)
            doc.close()
        else:
            with Image.open(tmp_path) as img:
                txt = pytesseract.image_to_string(img, lang='por+eng')
                texts.append(txt)
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)

    full_text = "\n\n".join(texts)
    return render_template_string(RESULT_HTML, filename=original_name, text=full_text)

@app.route('/gerar_html', methods=['POST'])
def gerar_html():
    texto_ocr = request.form.get('ocr_texto', '')
    if not texto_ocr.strip():
        return "Texto vazio.", 400

    html_resultado = gerar_html_acessivel_com_gemini(texto_ocr)
    
    return render_template_string(RESULT_HTML, filename="Documento Adaptado", text=html_resultado)

@app.route('/ask_ai_voice', methods=['POST'])
def ask_ai_voice():
    if 'audio' not in request.files:
        return "Nenhum arquivo de Ã¡udio recebido.", 400

    audio_file = request.files['audio']
    audio_data = audio_file.read()

    r = sr.Recognizer()
    try:
        audio_segment = AudioSegment.from_file(io.BytesIO(audio_data))
        
        # Usa a pasta temporÃ¡ria customizada especificada no inÃ­cio do script
        # O parÃ¢metro 'dir' direciona tempfile para usar essa pasta
        with tempfile.NamedTemporaryFile(delete=True, suffix=".wav", dir=CUSTOM_TEMP_DIR) as temp_wav_file:
            audio_segment.export(temp_wav_file.name, format="wav", codec="pcm_s16le")
            temp_wav_file.seek(0)
            
            with sr.AudioFile(temp_wav_file.name) as source:
                audio_listened = r.record(source)

            user_question = r.recognize_google(audio_listened, language='pt-BR')
            print(f"Pergunta do usuÃ¡rio: {user_question}")

            audio_response_buffer, ai_text_response = ask_gemini_and_get_audio(user_question)
            print(f"Resposta da IA: {ai_text_response}")

            return send_file(audio_response_buffer, mimetype='audio/wav', as_attachment=False)

    except sr.UnknownValueError:
        print("NÃ£o foi possÃ­vel entender o Ã¡udio.")
        return "NÃ£o foi possÃ­vel entender sua fala. Poderia repetir?", 400
    except sr.RequestError as e:
        print(f"Erro no serviÃ§o de reconhecimento de fala; verifique sua conexÃ£o com a internet: {e}")
        return f"Erro no serviÃ§o de reconhecimento de fala: {e}", 500
    except Exception as e:
        print(f"Ocorreu um erro geral na rota /ask_ai_voice: {e}")
        return f"Ocorreu um erro inesperado: {e}", 500

if __name__ == '__main__':
    app.run(debug=True)
